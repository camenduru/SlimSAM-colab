{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/SlimSAM-colab/blob/main/SlimSAM_colab.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!git clone -b dev https://github.com/camenduru/SlimSAM\n",
        "%cd /content/SlimSAM\n",
        "!pip install -e .\n",
        "!rm -rf /content/SlimSAM/checkpoints\n",
        "!git clone https://huggingface.co/camenduru/SlimSAM /content/SlimSAM/checkpoints\n",
        "!sed -i 's/input, approximate=self.approximate/input/g' /usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py\n",
        "# !python inference.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from segment_anything import SamPredictor, sam_model_registry, SamAutomaticMaskGenerator\n",
        "from segment_anything_kd.modeling.image_encoder import add_decomposed_rel_pos\n",
        "import matplotlib.pyplot as plt\n",
        "import torch_pruning as tp\n",
        "\n",
        "def calculate_iou(mask1, mask2):\n",
        "    \"\"\"\n",
        "    Calculate Intersection over Union (IoU) for two binary masks.\n",
        "\n",
        "    Parameters:\n",
        "        mask1 (numpy.ndarray): The first binary mask.\n",
        "        mask2 (numpy.ndarray): The second binary mask.\n",
        "\n",
        "    Returns:\n",
        "        float: The IoU score.\n",
        "    \"\"\"\n",
        "    # Make sure the input masks have the same shape\n",
        "    assert mask1.shape == mask2.shape, \"Both masks must have the same shape.\"\n",
        "\n",
        "    # Calculate the intersection and union of the masks\n",
        "    intersection = np.logical_and(mask1, mask2)\n",
        "    union = np.logical_or(mask1, mask2)\n",
        "\n",
        "    # Compute the IoU score\n",
        "    iou_score = np.sum(intersection) / np.sum(union)\n",
        "\n",
        "    return iou_score\n",
        "\n",
        "def show_mask(mask, ax, random_color=False):\n",
        "    if random_color:\n",
        "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
        "    else:\n",
        "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
        "    h, w = mask.shape[-2:]\n",
        "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
        "    ax.imshow(mask_image)\n",
        "\n",
        "def show_points(coords, labels, ax, marker_size=375):\n",
        "    pos_points = coords[labels==1]\n",
        "    neg_points = coords[labels==0]\n",
        "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "\n",
        "def show_box(box, ax):\n",
        "    x0, y0 = box[0], box[1]\n",
        "    w, h = box[2] - box[0], box[3] - box[1]\n",
        "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))\n",
        "\n",
        "def show_anns(anns):\n",
        "    if len(anns) == 0:\n",
        "        return\n",
        "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
        "    ax = plt.gca()\n",
        "    ax.set_autoscale_on(False)\n",
        "\n",
        "    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n",
        "    img[:,:,3] = 0\n",
        "    for ann in sorted_anns:\n",
        "        m = ann['segmentation']\n",
        "        color_mask = np.concatenate([np.random.random(3), [0.35]])\n",
        "        img[m] = color_mask\n",
        "    ax.imshow(img)\n",
        "\n",
        "def test_model():\n",
        "\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"CUDA visible devices: \" + str(torch.cuda.device_count()))\n",
        "    print(\"CUDA Device Name: \" + str(torch.cuda.get_device_name(device)))\n",
        "\n",
        "    # teacher_model_type = 'vit_b'\n",
        "    # checkpoint = 'checkpoints/sam_vit_b_qkv.pth'\n",
        "    # teacher_model = sam_model_registry[teacher_model_type](checkpoint=checkpoint)\n",
        "    # teacher_model.to(device)\n",
        "    # teacher_model.eval()\n",
        "\n",
        "    model_path = \"checkpoints/SlimSAM-77.pth\"\n",
        "    SlimSAM_model = torch.load(model_path)\n",
        "    SlimSAM_model.image_encoder = SlimSAM_model.image_encoder.module\n",
        "    SlimSAM_model.to(device)\n",
        "    SlimSAM_model.eval()\n",
        "    print(\"model_path:\",model_path)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.patch_embed(x)\n",
        "        if self.pos_embed is not None:\n",
        "            x = x + self.pos_embed\n",
        "        for blk in self.blocks:\n",
        "            x,qkv_emb,mid_emb,x_emb = blk(x)\n",
        "        x = self.neck(x.permute(0, 3, 1, 2))\n",
        "        return x\n",
        "\n",
        "    import types\n",
        "    funcType = types.MethodType\n",
        "    SlimSAM_model.image_encoder.forward = funcType(forward, SlimSAM_model.image_encoder)\n",
        "    example_inputs = torch.randn(1, 3, 1024, 1024).to(device)\n",
        "    ori_macs, ori_size = tp.utils.count_ops_and_params(SlimSAM_model.image_encoder, example_inputs)\n",
        "    print(\"MACs(G):\",ori_macs/1e9,\"Params(M):\",ori_size/1e6)\n",
        "\n",
        "    #mask_generator = SamAutomaticMaskGenerator(teacher_model)\n",
        "    mask_generator = SamAutomaticMaskGenerator(\n",
        "    model=SlimSAM_model,\n",
        "    points_per_side=32,\n",
        "    pred_iou_thresh=0.85,\n",
        "    stability_score_thresh=0.90,\n",
        "    crop_n_layers=1,\n",
        "    crop_n_points_downscale_factor=2,\n",
        "    min_mask_region_area=100,  # Requires open-cv to run post-processing\n",
        ")\n",
        "    predictor = SamPredictor(SlimSAM_model)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        path = 'images/truck.jpg'\n",
        "        print(path)\n",
        "        image = cv2.imread(path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        predictor.set_image(image)\n",
        "\n",
        "################ Point Prompt ################\n",
        "        input_point = np.array([[750, 370]])\n",
        "        input_label = np.array([1])\n",
        "        masks, scores, logits = predictor.predict(\n",
        "        point_coords=input_point,\n",
        "        point_labels=input_label,\n",
        "        box = None,\n",
        "        multimask_output=False,\n",
        "    )\n",
        "        plt.figure(figsize=(15,10))\n",
        "        plt.imshow(image)\n",
        "        show_mask(masks, plt.gca())\n",
        "        show_points(input_point, input_label, plt.gca())\n",
        "        plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"images/\"+'demo_point' + \".png\")\n",
        "\n",
        "################ Box Prompt ################\n",
        "        input_box = np.array([75, 275, 1725, 850])\n",
        "        masks, scores, logits = predictor.predict(\n",
        "        point_coords=None,\n",
        "        point_labels=None,\n",
        "        box = input_box,\n",
        "        multimask_output=False,\n",
        "    )\n",
        "        plt.figure(figsize=(15,10))\n",
        "        plt.imshow(image)\n",
        "        show_mask(masks, plt.gca())\n",
        "        show_box(input_box, plt.gca())\n",
        "        plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"images/\"+'demo_box' + \".png\")\n",
        "\n",
        "################ Segment everything prompt ################\n",
        "        masks = mask_generator.generate(image)\n",
        "        plt.figure(figsize=(15,10))\n",
        "        plt.imshow(image)\n",
        "        show_anns(masks)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"images/\"+\"demo_everything\" + \".png\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    test_model()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
